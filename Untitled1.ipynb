{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfalcon/pytorch_challenge/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dAoqCa_Ubg3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#check the GPU\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs =GPU.getGPUs()\n",
        "gpu=GPUs[0]\n",
        "for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "def printm():\n",
        "\tprocess = psutil.Process(os.getpid())\n",
        "\tprint(\"Gen RAM Free:\"+humanize.naturalsize(psutil.virtual_memory().available)) \n",
        "  # for i, gpu in enumerate(GPUs):\n",
        "  #   print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "   \n",
        "\n",
        "printm()\n",
        "\n",
        "#!pip install Pillow\n",
        "!pip uninstall -y PILLOW\n",
        "!pip install -U pillow\n",
        "!pip install Pillow==5.3.0\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mrcfRhUbq8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "# Define function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "    \n",
        "# Execute function\n",
        "mem_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QONMuo31bt5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#install the Pytorch Modules\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "#print(accelerator)\n",
        "if accelerator == 'cu92':\n",
        "   accelerator=\"cu91\"\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Gadmu7mbwOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3L6lvg8byOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "# Copy the Pytroch_challenge and data\n",
        "! cp -R \"/gdrive/My Drive/Colab Notebooks/pytorch_challenge\" .\n",
        "# Unzip the flower_data\n",
        "!unzip pytorch_challenge/flower_data.zip -d pytorch_challenge\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20qO1O1kb82O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "import torch\n",
        "import numpy as np\n",
        "import time \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "print(torch.__version__)    \n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hkU-cIVcG6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('pytorch_challenge/cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXJs8S9ycAUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define training and test data directories\n",
        "data_dir = 'vggnet_transfer/flower_photos/'\n",
        "train_dir = os.path.join(data_dir, 'train/')\n",
        "test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "data_dir = 'pytorch_challenge/flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/valid'\n",
        "\n",
        "print(train_dir)\n",
        "print(valid_dir)\n",
        "\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = cat_to_name.keys()#['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EH1gjCw5cew-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and transform data using ImageFolder\n",
        "\n",
        "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
        "data_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "\n",
        "# print out some data stats\n",
        "print('Num training images: ', len(train_data))\n",
        "print('Num valid images: ', len(valid_data))\n",
        "print('Num test images: ', len(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dK_sM_lkcwK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define dataloader parameters\n",
        "batch_size = 20\n",
        "num_workers=0\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_EF_BOyc9wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize some sample data\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}